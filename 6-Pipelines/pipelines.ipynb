{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Workshop\n",
    "### _**Pipelines**_\n",
    "\n",
    "---\n",
    "In this part of the workshop we will all our previous work from the labs and will automate the whole ML workflow. With that we can make the whole process more robust and any updates to the data preparation, modeling, evaluation, inference and monitoring will be put into production faster and more reliable.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#background) - Getting the work from previous labs.\n",
    "2. [Create the training pipeline](#Create_pipeline)\n",
    "    * [SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html)\n",
    "3. [Exercise](#a_Exercise) - adding steps to the pipeline\n",
    "4. [Create the end-to-end solution automatically](#SM_Projects)\n",
    "    * [SageMaker Project](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects.html) - Create end-to-end ML solutions with CI/CD by using SageMaker projects.\n",
    "    * customize the project with our pipeline and code\n",
    "\n",
    "---\n",
    "<a id='background'></a>\n",
    "\n",
    "## Background\n",
    "\n",
    "In the previous labs we created multiple resources to prepare the data (_2-DataPrep_), train the model (_3-Modeling_), evaluate model performance (_4-Evaluation_), deploy and customize inference logic (_4-Deployment/RealTime_) and monitor the deployed model (_5-Monitoring_).\n",
    "\n",
    "Now it's time to **bring everything together**!\n",
    "\n",
    "We will create a pipeline with 5 steps:\n",
    "\n",
    "1. Data preparation\n",
    "2. Training\n",
    "3. Evaluation\n",
    "4. Approve model\n",
    "5. Save to model registry step\n",
    "\n",
    "We will build our pipeline iterating little by little.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - if you _skipped_ some/all of the previous labs, follow instructions:\n",
    "\n",
    "   - **run this [notebook](./config/pre_setup.ipynb)**\n",
    "\n",
    "---\n",
    "Load all variables (and modules) for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket\n",
    "%store -r prefix\n",
    "%store -r region\n",
    "%store -r docker_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket, prefix, region, docker_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supress default INFO logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Create data preparation step\n",
    "\n",
    "Get the raw data location and the S3 URI where our code for data preparation was stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r s3uri_raw\n",
    "%store -r s3_dataprep_code_uri\n",
    "s3uri_raw, s3_dataprep_code_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first step will receive some inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for data preparation step\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=s3uri_raw # S3 URI where we stored the raw data\n",
    ")\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\", default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_labs_solutions.dataprep_solution import get_dataprep_processor\n",
    "sklearn_processor = get_dataprep_processor(processing_instance_type, processing_instance_count)\n",
    "sklearn_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing step for feature engineering\n",
    "step_process = ProcessingStep(\n",
    "    name=\"CustomerChurnProcess\",  # choose any name\n",
    "    processor=sklearn_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\", source=\"/opt/ml/processing/validation\"\n",
    "        ),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=s3_dataprep_code_uri,\n",
    "    job_arguments=[\"--input-data\", input_data],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the first iteration of the Pipeline\n",
    "\n",
    "We will create a simple pipeline that receives some inputs and just have 1 data preparation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, gmtime\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.step_collections import RegisterModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can associate SageMaker Experiments with Pipelines to help track multiple moving pieces (ML hyperparameters, data, artifacts, plots, metrics, etc. - a.k.a. [ML lineage tracking](https://docs.aws.amazon.com/sagemaker/latest/dg/lineage-tracking.html)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configs\n",
    "create_date = lambda: strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "experiment_name=f\"pipeline-customer-churn-prediction-xgboost-{create_date()}\"\n",
    "trial_name=f\"pipeline-framework-trial-{create_date()}\"\n",
    "pipeline_name = \"ChurnMLPipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_experiment_config = PipelineExperimentConfig(\n",
    "    experiment_name = experiment_name,\n",
    "    trial_name = trial_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with just input parameters and 1 step for data prep\n",
    "pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            input_data,\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "        ],\n",
    "        steps=[step_process],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that pipeline was configured correctly and load its definition\n",
    "import json\n",
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#### Ok, looks good. Let's create the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to the pipeline and see its DAG:\n",
    "\n",
    "<img src=\"./media/sm-pipeline.png\" width=\"50%\">\n",
    "\n",
    "2. Right-click the ChurnMLPipeline -> `Open pipeline details`.\n",
    "\n",
    "Check its DAG (with just the data prep step:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-1.png\" width=\"50%\">\n",
    "\n",
    "3. Click on `Parameters` to see the default parameter inputs for a execution:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-1-params.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember that we set the inputs as:\n",
    "```python\n",
    "# Parameters for data preparation step\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=s3uri_raw # S3 URI where we stored the raw data\n",
    ")\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\", default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Let's programatically execute the pipeline with defaults:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to wait for execution to end:\n",
    "# execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Right-click the `Executions` tab:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-1-exec-list.png\" width=\"100%\">\n",
    "\n",
    "5. Select the only execution (should be in status \"Executing\") and double click on it:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-1-exec.png\" width=\"60%\">\n",
    "\n",
    "6. Wait for a few minutes (for the data preparation step and the SageMaker Processing Job under the hood to finish):\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-1-exec-succ.png\" width=\"60%\">\n",
    "\n",
    "7. If you go to `Experiments and trials` tab you will see that SageMaker Pipelines created an experiment called `churnmlpipeline`.\n",
    "\n",
    "Also if we select our data prep Processing job, we can see that it correctly created 3 dataset as output: `train`, `validation` and `test`:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-1-exec-outs.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Create modeling step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r s3_modeling_code_uri\n",
    "%store -r train_script_name\n",
    "s3_modeling_code_uri, train_script_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_labs_solutions.modeling_solution import get_modeling_estimator\n",
    "\n",
    "xgb_train = get_modeling_estimator(bucket,\n",
    "                                   prefix,\n",
    "                                   s3_modeling_code_uri, \n",
    "                                   docker_image_name,\n",
    "                                   entry_point_script = train_script_name)\n",
    "xgb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"CustomerChurnTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"train\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\"\n",
    "                 ),\n",
    "        \"validation\": TrainingInput(\n",
    "                    s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"validation\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\"\n",
    "                 )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can link one step's output to other steps input by accessing the properties:\n",
    "```python\n",
    "# Get output from processing step with key `train`\n",
    "step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the second iteration of the Pipeline (updating the definition)\n",
    "\n",
    "We will update the pipeline adding an input parameter for the training Step and also the training Step itself, resulting in a pipeline with 2 step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an input parameter to define the training instance type\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "    ],\n",
    "    steps=[step_process, step_train],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the pipeline\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If we go to the pipeline and click on the refresh button, we see now its 2 steps and the new input parameter:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2.png\" width=\"70%\">\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2-params.png\" width=\"100%\">\n",
    "\n",
    "2. Now, let's execute the new pipeline in the Studio UI. Click on `Start an execution`:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2-exec.png\" width=\"80%\">\n",
    "\n",
    "3. The default input configurations should appear in the Studio UI. Click on `Start`:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2-exec-man.png\" width=\"80%\">\n",
    "\n",
    "4. Refreshing the executions we should see:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2-exec-man2.png\" width=\"80%\">\n",
    "\n",
    "5. Click on `View details` or select the execution in the list (status \"Executing\") and double click:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2-exec-man3.png\" width=\"80%\">\n",
    "\n",
    "6. Wait a few minutes to the data prep Processing job and the training job finish. You should see this:\n",
    "\n",
    "<img src=\"./media/sm-pipe-iter-2-exec-succ.png\" width=\"80%\">\n",
    "\n",
    "If you click on the training step and select `Outputs` you will also be able to see the final training and validation log losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_labs_solutions.evaluation_solution import get_evaluation_processor\n",
    "script_eval = get_evaluation_processor(docker_image_name)\n",
    "script_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r s3url_test\n",
    "%store -r s3_evaluation_code_uri\n",
    "s3url_test, s3_evaluation_code_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing step for evaluation\n",
    "step_eval = ProcessingStep(\n",
    "        name=\"CustomerChurnEval\",\n",
    "        processor=script_eval,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"\n",
    "            ),\n",
    "        ],\n",
    "        code=os.path.join(BASE_DIR, \"evaluate.py\"),\n",
    "        property_files=[evaluation_report],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, notice that we get the model from the training step and also the test dataset from the data preparation step:\n",
    "```python\n",
    "# Get output model artifact from training step\n",
    "step_train.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "# Get the test dataset - the output of data preparation step with key `test`\n",
    "step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the third iteration of the Pipeline (updating the definition)\n",
    "\n",
    "We will update the pipeline adding the evaluation step, resulting in a pipeline with 3 step: data prep, training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "        name=\"test\",\n",
    "        steps=[step_train, step_eval]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create approve model and save to model registry steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import (\n",
    "    ConditionGreaterThanOrEqualTo,\n",
    ")\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, gmtime\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "from sagemaker.workflow.step_collections import RegisterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configs\n",
    "create_date = lambda: strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "experiment_name=f\"pipeline-customer-churn-prediction-xgboost-{create_date()}\"\n",
    "trial_name=f\"pipeline-framework-trial-{create_date()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_experiment_config = PipelineExperimentConfig(\n",
    "    experiment_name = experiment_name,\n",
    "    trial_name = trial_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\",  # ModelApprovalStatus can be set to a default of \"Approved\" if you don't want manual approval.\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=f\"s3://EXAMPLE-BUCKET/PATH/TO/RawData.csv\",  # Change this to point to the s3 location of your raw input data.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            model_approval_status,\n",
    "            input_data,\n",
    "        ],\n",
    "        steps=[step_process, step_train, step_eval, step_cond],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute with defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_json = sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "    step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "))\n",
    "json.loads(evaluation_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run another time with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get estimators and processors from previous labs\n",
    "# add other metrics in eval and also graphics\n",
    "# send hyperparamenters to Pipeline as parameter (I believe it's possible sending in InputConfig)\n",
    "# Pipeline load definition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SM_Projects'></a>\n",
    "# Customizing the Build/Train/Deploy MLOps Project Template\n",
    "\n",
    "We recently announced [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/), the first \n",
    "purpose-built, easy-to-use Continuous Integration and Continuous Delivery (CI/CD) service for machine learning. \n",
    "SageMaker Pipelines has three main components which improves the operational resilience and reproducibility of your \n",
    "workflows: Pipelines, Model Registry, and Projects. \n",
    "\n",
    "SageMaker Projects introduce MLOps templates that automatically provision the underlying resources needed to enable \n",
    "CI/CD capabilities for your Machine Learning Development Lifecycle (MLDC). Customers can use a number of built-in \n",
    "templates or create your own custom templates.\n",
    "\n",
    "This example will focus on using one of the MLOps templates to bootstrap your ML project and establish a CI/CD \n",
    "pattern from seed code. We’ll show how to use the built-in Build/Train/Deploy Project template as a base for a \n",
    "customer churn classification example. This base template will enable CI/CD for training machine learning models, \n",
    "registering model artifacts to the Model Registry, and automating model deployment with manual approval and automated \n",
    "testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLOps Template for Build, Train, and Deploy\n",
    "\n",
    "We’ll start by taking a detailed look at what AWS services are launched when this build, train, deploy MLOps template \n",
    "is launched. Later, we’ll discuss how the skeleton can be modified for a custom use case. \n",
    "\n",
    "To get started with SageMaker Projects, [they must be first enabled in the SageMaker Studio console](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-studio-updates.html). \n",
    "This can be done for existing users or while creating new ones:\n",
    "\n",
    "<img src=\"media/enable_projects.png\">\n",
    "\n",
    "Within Amazon SageMaker Studio, you can now select “Projects” from a drop-down menu on the “Components and registries” \n",
    "tab as shown below:\n",
    "\n",
    "<img src=\"media/select_projects.png\">\n",
    "\n",
    "From the projects page you’ll have the option to launch a pre-configured SageMaker MLOps template. We'll select the build, train and deploy template:\n",
    "\n",
    "<img src=\"media/create_project.png\">\n",
    "\n",
    "NOTE: Launching this template will kick off a model building pipeline by default and will train a regression model. This will incur a small cost.\n",
    "\n",
    "Once the project is created from the MLOps template, the following architecture will be deployed:\n",
    "\n",
    "<img src=\"media/deep_dive.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the Seed Code for Custom Use Case\n",
    "\n",
    "After your project has been created the architecture shown above will be deployed and the visualization of the \n",
    "Pipeline will be available in the “Pipelines” drop down menu within SageMaker Studio.\n",
    "\n",
    "In order to modify the seed code from this launched template, we’ll first need to clone the AWS CodeCommit \n",
    "repositories to our local SageMaker Studio instance. From the list of projects, select the one that was just \n",
    "created. Under the “Repositories” tab you can select the hyperlinks to locally clone the AWS CodeCommit repos:\n",
    "\n",
    "<img src=\"media/clone_repos.png\">\n",
    "\n",
    "\n",
    "### ModelBuild Repo\n",
    "\n",
    "The SageMaker project template will create this repositories.\n",
    "\n",
    "In the `...-modelbuild` repository there's the code for preprocessing, training, and evaluating the model. \n",
    "The seed code trains and evaluates a model on the [UCI Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone):\n",
    "\n",
    "<img src=\"media/repo_directory.png\">\n",
    "\n",
    "\n",
    "**In our case we want to create a pipeline for predicting Churn (part 1 of the lab).** We can modify these files in order to solve our own customer churn use-case.\n",
    "\n",
    "\n",
    "We’ll need a dataset accessible to the project (_Churn dataset_). \n",
    "\n",
    "The easiest way to do this is run the following in our notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok, now we have donwloaded the Churn dataset and uploaded it to our S3 Bucket that is accessible to the SageMaker Project role.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Modifying the code for the Churn problem\n",
    "\n",
    "This is the sample structure of the Project (Abalone):\n",
    "\n",
    "<img src=\"media/repo_directory.png\">\n",
    "\n",
    "\n",
    "#### We'll need to:\n",
    "1. rename the `abalone` directory to `customer_churn`\n",
    "2. replace `codebuild-buildspec.yml` in your current Studio project (Abalone) with the one found in [modelbuild/codebuild-buildspec.yml](modelbuild/codebuild-buildspec.yml) (Churn)\n",
    "3. replace the `preprocess.py`, `evaluate.py` (of the sample Abalone) with the ones found in `modelbuild/pipelines/customer_churn`\n",
    "4. replace `pipeline.py`(Abalone) with the one found in `modelbuild/pipelines/customer_churn/pipeline.py`\n",
    "\n",
    "    \n",
    "5. **In the `pipeline.py` file you'll need to replace the `default_value` of `InputDataURL` with the URL you obtained when uploading the data above.**\n",
    "    \n",
    "```python\n",
    "#in pipeline.py\n",
    "...\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=f\"s3://EXAMPLE-BUCKET/PATH/TO/RawData.csv\",  # Change this to point to the s3 location of your raw input data.\n",
    ")\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger a new training Pipeline Execution through git commit\n",
    "\n",
    "By committing these changes to the AWS CodeCommit repository (easily done in SageMaker Studio source control tab), a \n",
    "new Pipeline execution will be triggered since there is an EventBridge monitoring for commits.  After a few moments, \n",
    "we can monitor the execution by selecting your Pipeline inside of the SageMaker Project.\n",
    "\n",
    "<img src=\"media/git_push.png\">\n",
    "\n",
    "This triggers the pipelines for training. Go to our `“Pipelines”` tab inside of the SageMaker Project. Click on our only pipeline. And you'll see:\n",
    "\n",
    "<img src=\"media/execute_pipeline.png\">\n",
    "\n",
    "Select the most recent execution:\n",
    "\n",
    "<img src=\"media/dag.png\">\n",
    "\n",
    "\n",
    "## Trigger the ModelDeploy Pipeline\n",
    "\n",
    "Once the train pipeline is completed, we can go to our `“Model groups”` tab inside of the SageMaker Project and inspect the metadata attached to the model artifacts. If everything looks good, we can manually approve the model:\n",
    "\n",
    "<img src=\"media/model_metrics.png\">\n",
    "\n",
    "<img src=\"media/approve_model.png\">\n",
    "\n",
    "This approval will trigger the ModelDeploy pipeline (in CodePipeline):\n",
    "\n",
    "<img src=\"media/execute_pipeline_deploy.png\">\n",
    "\n",
    "After we deploy to a staging environment and run some tests, we will have to **approve the deployment to production** by approving in the `ApproveDeployment` stage:\n",
    "\n",
    "<img src=\"media/approve_deploy_prod.png\">\n",
    "\n",
    "\n",
    "\n",
    "Finally, if we go back to Studio, we will see the Production endpoint for real time inference.\n",
    "\n",
    "<img src=\"media/endpoints.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
